<!DOCTYPE HTML>
<html>
    <head>
        <title>Learning to Climb: Constrained Contextual Bayesian Optimisation on a Multi-Modal Legged Robot</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="flickity.css">
        <link rel="stylesheet" href="style.css" />
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');
        </script>
        <script src="flickity.pkgd.js"></script>
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
            </header>
            <!-- style="padding-bottom:1em" -->
            <div id="profile">
                <!-- <img src="images/profile.jpg"> -->
                <div id="profile-desc">
                    <div id="profile-name">Learning to Climb: Constrained Contextual Bayesian Optimisation on a Multi-Modal Legged Robot
                        <p><br>Accepted by IEEE RA-L / IROS 2022 &nbsp &nbsp <a href="https://ieeexplore.ieee.org/document/9835039">Full Paper</a></p>
                    </div>
                    <p>
                        <b>Abstract</b>. Controlling a legged robot to climb obstacles with different heights is challenging, but important for an autonomous robot to work in an unstructured environment. In this paper, we model this problem as a novel contextual constrained multi-armed bandit framework. We further propose a learning-based Constrained Contextual Bayesian Optimisation (CoCoBo) algorithm that can solve this class of problems effectively.  CoCoBo models both the reward function and constraints as Gaussian processes, incorporate continuous context space and action space into each Gaussian process, and find the next training samples through excursion search.  The experimental results show that CoCoBo is more data-efficient and safe, compared to other related state-of-the-art optimisation methods, on both synthetic test functions and real-world experiments. The real-world results—our robot could successfully learn to climb an obstacle higher than itself—reveal that our method has an enormous potential to allow self-adaptive robots to work in various terrains.   
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section paper">
                <!-- <h1>Highlights</h1> -->
                <p align="center">
                <iframe width="820" height="461.25" src="https://www.youtube.com/embed/Pn-uevQhCGw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </p>
            </div>
            <br>
            <div class="divider"></div>

            <div class="section paper">
                <h1>Learning Process</h1>
                <p>Visualisation of the learning process of Branin-Hoo test function from CoCoBo. We treat the first dimension of the Branin-Hoo function as state space and the second as action space; we also flip the state axis to create a variant of Branin-Hoo. The heat maps visualise the test functions and the contour lines demonstrate the constraint functions. We want to find the optimum state for every action and hence the optimum policy. We visualise the learnt policy (the pink solid line) compared with the ground-true optimum (the yellow dash line); and the training samples that are valid (white dots) and invalid (white crosses). The learnt policy successfully find the pattern of the contextual optimum and avoid the invalid regions in both test functions.<br></p>
                    <!-- <font color="4e79a7">&#9733; Plenary Talk, Best Paper Presentation Award Finalist, CoRL &#9733;</font></p><br> -->
                <img src="animation/b_movie.gif">
                <img src="animation/f_movie.gif">
            </div>
            <div class="divider"></div>


            
            

            <div class="divider"></div>  
            <div class="section paper">
                <h1>Synthetic Results</h1>
                <p>CoCoBo clearly outperforms all the other methods with respect to average simple regret in all cases—except Hartmann3-3, where all methods report a generally high regret. </p>
                
                
                    <div class="main-carousel" data-flickity='{ "cellAlign": "left", "contain": true, "wrapAround": true, "autoPlay": 3000, "groupCells": true, "groupCells": 1, "prevNextButtons": true, "pageDots": false, "resize": false}'>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/0-B11.png" alt="grapes" width="600" height="600"/>
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/1-FB11.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/2-H13.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/3-H22.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/3-H22.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/4-H31.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/5-H15.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/6-H24.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/synthetics/7-H33.png" alt="grapes" width="600" height="600" />
                    </div>

                </div>
                
            </div>

            <br>
            <br>
            <div class="divider"></div>

            <div class="divider"></div>  
            <div class="section paper">
                <h1>Experimental Results</h1>
                <p>CoCoBo reaches the highest number of total evaluations during the training process (50 steps) and consistently achieves lower or equivalent regret in each individual state than other methods.  </p>
                
                
                    <div class="main-carousel" data-flickity='{ "cellAlign": "left", "contain": true, "wrapAround": true, "autoPlay": 3000, "groupCells": true, "groupCells": 1, "prevNextButtons": true, "pageDots": false, "resize": false}'>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/reals/real0.png" alt="grapes" width="600" height="600"/>
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/reals/real1.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/reals/real2.png" alt="grapes" width="600" height="600" />
                    </div>

                </div>
                
            </div>

            <br>
            <br>
            <div class="divider"></div>

            <!-- <div class="section paper">
                <h1>Experimental Results</h1>
                <p>Latest version (Oct 28, 2020): <a href="https://arxiv.org/abs/2010.14406">arXiv:2010.14406 [cs.RO]</a>.<br>Published at the Conference on Robot Learning (CoRL) 2020<br>
                    <font color="4e79a7">&#9733; Plenary Talk, Best Paper Presentation Award Finalist, CoRL &#9733;</font></p><br>
                <a href="https://arxiv.org/pdf/2010.14406.pdf"><img src="images/thumbnail-half.jpg"></a>
            </div>
            <div class="divider"></div> -->

            <div class="section paper half">
                <h1>Code</h1>
                <p>
                    Code is available on Github. Includes:<br>
                    <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp;3D models (STL files for 3D printing and OBJ files for simulation).<br> -->
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/CoCoBo/tree/botorch0.6">Training/testing code</a> (with BoTorch/Python).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/Cheetah-Gym">Simulation environments</a> (with PyBullet).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/Cheetah-Software-RL">Program on the real robot</a> (with TensorFlow/C++).<br><br>
                    <br>
                </p>

            </div>

           
            <div class="section bibtex half">
                <h1>Bibtex</h1>
                <div class="code">@article{yu2022learning,<br>
                &nbsp;&nbsp;&nbsp;&nbsp;title={Learning to Climb: Constrained Contextual Bayesian Optimisation on a Multi-Modal Legged Robot},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;author={Yu, Chen and Cao, Jinyue and Rosendo, Andre},<br>
                <!-- &nbsp;&nbsp;&nbsp;&nbsp;journal={XXX},<br> -->
                &nbsp;&nbsp;&nbsp;&nbsp;year={2022},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;volume={7},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;number={4},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;pages={9881-9888},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;doi={10.1109/LRA.2022.3192798}<br>
                }</div>
            </div>    
            <div class="divider"></div>
            <!-- <div class="section team">
                <h1>Team</h1>
                <div class="people-profile">
                    <a href="https://andyzeng.github.io/"><img src="images/people/andy.jpg"><p>Andy Zeng</p></a>
                </div>
                <div class="people-profile">
                    <a href="http://www.peteflorence.com/"><img src="images/people/pete.jpg"><p>Pete Florence</p></a>
                </div>
                <div style="clear: both;"></div>
            </div> -->
            <!-- <div class="section teamlogo">
                <img src="images/logo.png">
                <p>Robotics at Google</p>
            </div>
            <div style="clear: both;"></div> -->
            <div class="divider"></div>
            
            <!-- <div class="section highlights">
                <h1>Highlights</h1>
                <a href="https://ai.googleblog.com/2021/02/rearranging-visual-world.html"><img style="height: 80px; margin-left: 30px; margin-bottom: 10px" src="images/aiblog.png"></a>
                <a href="https://venturebeat.com/2020/10/28/googles-transporter-networks-learn-to-stack-blocks-and-assemble-mouthwash-kits-from-as-few-examples/"><img style="height: 26px; margin-top: 31px; margin-left: 30px; margin-bottom: 10px" src="images/vb.png"></a>
            </div>
            <div style="clear: both;"></div>
            <div class="divider"></div>
            
            <div class="section video">
                <h1>Plenary Talk</h1>
                <p>Watch it on YouTube (<a href="https://youtu.be/8afHfReCfPo?t=12214">link</a>)<br><a href="https://youtu.be/8afHfReCfPo?t=12214"><img src="images/talk-thumbnail.png" width="640px" style="border: 2px solid #191e3f; margin-top: 10px"></a></p>
            </div>
            <div class="section video">
                <h1>Supplemental Video</h1>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/496UVuAdOP4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            <div class="section video">
                <h1>Method</h1>
                <video style="margin-left: 30px; width: 480px; margin-bottom: 30px" playsinline="" muted="" autoplay="" loop="">
                    <source src="images/animation.mp4" type="video/mp4">
                </video>
            </div>
            <div class="divider"></div> -->
            
            <!-- <div class="section acknowledgements">
                <h1>Acknowledgements</h1>
                <p>Special thanks to my computer for its hard working. </p><br><br>
            </div> -->
            <br><br><br><br><br><br><br><br><br><br>
            <div class="divider"></div>
        </div>
    </body>
</html>